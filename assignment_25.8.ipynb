{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "In this assignment, you continue working with the fashion MNIST dataset. Use the same sample of size 10000 with the previous checkpoint for the sake of comparability. To complete this assignment, submit a link to a Jupyter notebook containing your solutions to the following tasks below, and plan on discussing with your mentor. You can also take a look at these example solutions.\n",
    "\n",
    "1. Load the dataset and make your preprocessing like normalizing the data.\n",
    "\n",
    "2. Apply t-SNE to the data by setting n_components=2.\n",
    "\n",
    "3. Using the two-dimensional t-SNE representation, draw a graph of the data by coloring and labeling the data points as we did in the checkpoint.\n",
    "\n",
    "4. Do you think t-SNE solution is satisfactory? Can you distinguish between different classes easily? Which one has done a better job: t-SNE or the PCA you applied in the assignment of the previous checkpoint?\n",
    "\n",
    "5. Now, play with the different perplexity values and apply t-SNE for each of them. Which perplexity value is the best one in terms of the two-dimensional representation clarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the dataset and make your preprocessing like normalizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the MNIST dataset below\n",
    "mnist = fetch_openml(\"Fashion-MNIST\", version=1, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "indices = np.random.choice(70000, 10000)\n",
    "X = mnist.data[indices] / 255.0\n",
    "y = mnist.target[indices]\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Apply t-SNE to the data by setting n_components=2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(X)\n",
    "\n",
    "print(\"t-SNE done! Time elapsed: {} seconds\".format(time.time() - time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using the two-dimensional t-SNE representation, draw a graph of the data by coloring and labeling the data points as we did in the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "colours = [\"r\", \"b\", \"g\", \"c\", \"m\", \"y\", \"k\", \"r\", \"burlywood\", \"chartreuse\"]\n",
    "for i in range(tsne_results.shape[0]):\n",
    "    plt.text(\n",
    "        tsne_results[i, 0],\n",
    "        tsne_results[i, 1],\n",
    "        str(y[i]),\n",
    "        color=colours[int(y[i])],\n",
    "        fontdict={\"weight\": \"bold\", \"size\": 50},\n",
    "    )\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Do you think t-SNE solution is satisfactory? Can you distinguish between different classes easily? Which one has done a better job: t-SNE or the PCA you applied in the assignment of the previous checkpoint?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-SNE has done a much better job separating out the classes in the 2D visual representation than PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Now, play with the different perplexity values and apply t-SNE for each of them. Which perplexity value is the best one in terms of the two-dimensional representation clarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through different perplexity values to find the best one\n",
    "\n",
    "for j in [20, 30, 40, 50]:\n",
    "    time_start = time.time()\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=j, n_iter=300)\n",
    "    tsne_results = tsne.fit_transform(X)\n",
    "\n",
    "    print(\"t-SNE done! Time elapsed: {} seconds\".format(time.time() - time_start))\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    colours = [\"r\", \"b\", \"g\", \"c\", \"m\", \"y\", \"k\", \"r\", \"burlywood\", \"chartreuse\"]\n",
    "    for i in range(tsne_results.shape[0]):\n",
    "        plt.text(\n",
    "            tsne_results[i, 0],\n",
    "            tsne_results[i, 1],\n",
    "            str(y[i]),\n",
    "            color=colours[int(y[i])],\n",
    "            fontdict={\"weight\": \"bold\", \"size\": 50},\n",
    "        )\n",
    "\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In playing with different perplexities, none of them stand out as far superior to the rest in terms of visual clarity.  All of the perplexity values yield clear separation of some of the classes, and some are not very separable.  I'd say maybe 30 or 40 look the best, but it's hard to say.  In general, the higher the perplexity, the more tightly grouped the close stuff is, and the more spread out the extended structure is."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
